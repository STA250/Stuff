<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>STA 250 :: Advanced Statistical Computing (UCD, Fall 2013) by STA250</title>
    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
    <script src="javascripts/respond.js"></script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <!--[if lt IE 8]>
    <link rel="stylesheet" href="stylesheets/ie.css">
    <![endif]-->
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

  </head>
  <body>
      <div id="header">
        <nav>
          <li class="fork"><a href="https://github.com/STA250/Stuff">View On GitHub</a></li>
          <li class="downloads"><a href="https://github.com/STA250/Stuff/zipball/master">ZIP</a></li>
          <li class="downloads"><a href="https://github.com/STA250/Stuff/tarball/master">TAR</a></li>
          <li class="title">DOWNLOADS</li>
        </nav>
      </div><!-- end header -->

    <div class="wrapper">

      <section>
        <div id="title">
            <a href="http://sta250.github.io/Stuff"><h1>STA 250 :: Advanced Statistical Computing (UCD, Fall 2013)</h1></a>
          <p>Code + goodies used in Prof. Baines' STA 250 Course (UC Davis, Fall 2013)</p>
          <hr>
          <span class="credits left">Project maintained by <a href="https://github.com/STA250">STA250</a></span>
          <span class="credits right">Hosted on GitHub Pages &mdash; Theme by <a href="https://twitter.com/michigangraham">mattgraham</a></span>
        </div>

        <h1>
<a name="stuff" class="anchor" href="#stuff"><span class="octicon octicon-link"></span></a>Getting Started With Amazon Web Services (AWS)</h1>

<ul>
  <li>Once you receive an email from Prof. Baines with your AWS login and password, proceed to <a href="https://ucdsta250.signin.aws.amazon.com/console/">the AWS login page</a></li>

  <li>First, you need to create your key pair by going to:<br/>
  <a href="https://console.aws.amazon.com/ec2/">https://console.aws.amazon.com/ec2/</a> 
  </li>
  <li>Click on &quot;Key Pairs&quot; under &quot;Network &amp; Security&quot; in the left panel of the console.</li>
  <li>Click &quot;Create Key Pair&quot; and give your key a distinctive name (e.g., &quot;JimsKeyPair&quot;). The key will be created and you will be prompted to save the file to your computer.<br/><br/>
  <em>Keep this file safe, it will be your private key for logging into your EMR job.</em><br/><br/>
  </li>

  <li>Note: Only follow the next steps when you have written your mapper and reducer scripts and are ready to deploy your job.</li>
  <br/><br/>
  <li>Next, go to the Elastic MapReduce tab, and click to launch new work flow.</li>

  <li>Under the &quot;Create a Job Flow&quot; option, check &quot;Run Your Own Application&quot; and select &quot;Hive Program&quot;.</li>
  <li>Click &quot;Next&quot;, and then select &quot;Start an Interactive Hive Session&quot;.</li>
  <li>You should now be in the &quot;Configure EC2 Instances&quot; tab. For the Master Instance Group select &quot;Large&quot;, the Core Instance Group specify 4 &quot;Large&quot; instances. The Task Instance Group can be left unused. Click &quot;Next&quot;</li>
  <li>Under &quot;Advanced Options&quot; and &quot;Amazon EC2 Key Pair&quot; select the name of the key pair you created earlier and click &quot;Next&quot;.</li> 
  <li>For &quot;Bootstrap Actions&quot; select &quot;Configure your Bootstrap Actions&quot; and then &quot;Memory Intensive Configuration&quot; before clicking &quot;Continue&quot;.</li>
  <li>When everything is ready, click &quot;Create Job Flow&quot;.</li>

  <li>Go back to the EMR console and click refresh until your job has starts (it may take a few minutes). Click on the job name, and wait until the &quot;Master Public DNS Name&quot; appears. Copy the DNS, as this will be how you <code>ssh</code> into your instance. Using the DNS, <code>ssh</code> into your session as follows:<br/>
  <pre><code>
    ssh -i /path/to/yourkeypair.pem hadoop@ec2-xxxx.us-west-2.compute.amazonaws.com
  </code></pre>
  Where you need to replace the DNS with the one corresponding to your job.</li>
  <li>You are now logged into an interactive session on your Hadoop (&quot; Hive) configured cluster.</li>
  <li>To transfer files into your cluster run the following from your local machine:<br/>
  <pre><code>
    scp -i yourkey.pem file_to_copy hadoop@(amazon_dns):~/
  </code></pre>
  The above command assumes your private key file is stored in the directory from which you are
  ssh-ing (if not, just specify the full path), and you must replace <code>(amazon_dns)</code>
  with the public DNS shown in the AWS console. Similarly, to copy results back to your
  local machine upon completion:
  <pre><code>
    scp -i yourkey.pem hadoop@(amazon_dns):~/file_to_copy dest_to_copy_to
  </code></pre>
  </li>
  <li><em>Do not forget to terminate the session when you are done!!!</em></li>
</ul> 

<p>Happy coding! :)</p>
      </section>

    </div>
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->
    
  </body>
</html>
