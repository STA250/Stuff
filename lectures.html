<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>STA 250 :: Advanced Statistical Computing (UCD, Fall 2013) by STA250</title>
    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
    <script src="javascripts/respond.js"></script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <!--[if lt IE 8]>
    <link rel="stylesheet" href="stylesheets/ie.css">
    <![endif]-->
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

  </head>
  <body>
      <div id="header">
        <nav>
          <li class="fork"><a href="https://github.com/STA250/Stuff">View On GitHub</a></li>
          <li class="downloads"><a href="https://github.com/STA250/Stuff/zipball/master">ZIP</a></li>
          <li class="downloads"><a href="https://github.com/STA250/Stuff/tarball/master">TAR</a></li>
          <li class="title">DOWNLOADS</li>
        </nav>
      </div><!-- end header -->

    <div class="wrapper">

      <section>
        <div id="title">
            <a href="http://sta250.github.io/Stuff"><h1>STA 250 :: Advanced Statistical Computing (UCD, Fall 2013)</h1></a>
          <p>Code + goodies used in Prof. Baines' STA 250 Course (UC Davis, Fall 2013)</p>
          <hr>
          <span class="credits left">Project maintained by <a href="https://github.com/STA250">STA250</a></span>
          <span class="credits right">Hosted on GitHub Pages &mdash; Theme by <a href="https://twitter.com/michigangraham">mattgraham</a></span>
        </div>

        <h1>
<a name="stuff" class="anchor" href="#stuff"><span class="octicon octicon-link"></span></a>Course Website</h1>

<p>STA 250 Lectures</p>

<div style="float: left; width: 25%;">
<ul>
    <li>Slides</li>
    <li><a href="http://sta250.github.io/Stuff/Lecture_01">Lecture 01 Slides</a></li>
    <li><em>Boot Camp</em></li>
    <li><a href="http://sta250.github.io/Stuff/Lecture_02">Lecture 02 Slides</a></li>
    <li>Lecture 03</li>
    <li><em>Bayes Module</em></li>
    <li>Lecture 04</li>
    <li><a href="Lecture_05.pdf">Lecture 05</a> <a href="Lecture_05.tex">(tex)</a></li>
    <li><a href="Lecture_06.pdf">Lecture 06</a> <a href="Lecture_06.tex">(tex)</a></li>
    <li>Lecture 07</li>
    <li><em>Big Data Module</em></li>
    <li><a href="http://sta250.github.io/Stuff/Lecture_08">Lecture 08 Slides</a></li>
    <li><a href="http://sta250.github.io/Stuff/Lecture_09">Lecture 09 Slides</a></li>
    <li><a href="http://sta250.github.io/Stuff/Lecture_10">Lecture 10 Slides</a></li>
    <li><a href="http://sta250.github.io/Stuff/Lecture_11">Lecture 11 Slides</a></li>
    <li><em>EM Module</em></li>
    <li><a href="Lecture_12.pdf">Lecture 12</a> <a href="Lecture_12.tex">(tex)</a></li>
    <li><a href="Lecture_13.pdf">Lecture 13</a> <a href="Lecture_13.tex">(tex)</a></li>
    <li>Lecture 14</li>
    <li>Lecture 15</li>
</ul>
</div>
<div style="float: left; width: 25%;">
<ul>
    <li>Notetaker 1</li>
	<li>(No Notetaker)</li>
    <li></li>
	<li>Aden: <a href="notes/Lecture_02_Notes_Aden.md">md</a></li>
	<li>Izyumin: <a href="notes/Lecture_03_Notes_Izyumin.tex">tex</a>, <a href="notes/Lecture_03_Notes_Izyumin.pdf">pdf</a></li>
    <li></li>
	<li>Werner: <a href="notes/Lecture_04_Notes_Werner.tar.gz">tex</a>, <a href="notes/Lecture_04_Notes_Werner.pdf">pdf</a></li>
	<li>Rohosen: <a href="notes/Lecture_05_Notes_Bandyopadhyay.tex">tex</a>, <a href="notes/Lecture_05_Notes_Bandyopadhyay.pdf">pdf</a></li>
	<li>Meisner: <a href="notes/Lecture_06_Notes_Meisner.tex">tex</a>, <a href="notes/Lecture_06_Notes_Meisner.pdf">pdf</a></li>
	<li>Cai: <a href="notes/Lecture_07_Notes_Cai.tex">tex</a>, <a href="notes/Lecture_07_Notes_Cai.pdf">pdf</a></li>
    <li></li>
	<li>Fan: <a href="notes/Lecture_08_Notes_Fan.tex">tex</a>, <a href="notes/Lecture_08_Notes_Fan.pdf">pdf</a></li>
	<li>Shvarts: <a href="notes/Lecture_09_Notes_Shvarts.tar.gz">tex</a>, <a href="notes/Lecture_09_Notes_Shvarts.pdf">pdf</a></li>
	<li>Wang: <a href="notes/Lecture_10_Notes_Wang.tex">tex</a>, <a href="notes/Lecture_10_Notes_Wang.pdf">pdf</a></li>
	<li>Chen: <a href="notes/Lecture_11_Notes_Chen.tar.gz">tex</a>, <a href="notes/Lecture_11_Notes_Chen.pdf">pdf</a></li>
	<li></li>
	<li>Cheung: <a href="notes/Lecture_12_Notes_Cheung.tex">tex</a>, <a href="notes/Lecture_12_Notes_Cheung.pdf">pdf</a></li>
	<li>Shuo: <a href="notes/Lecture_13_Notes_Li.tex">tex</a>, <a href="notes/Lecture_13_Notes_Li.pdf">pdf</a></li>
	<li>(Coming soon...)</li>
	<li>Bissell: <a href="notes/Lecture_15_Notes_Bissell.tex">tex</a>, <a href="notes/Lecture_15_Notes_Bissell.pdf">pdf</a></li>
</ul>
</div>
<div style="float: left; width: 25%;">
<ul>
    <li>Notetaker 2</li>
	<li>(No Notetaker)</li>
    <li></li>
	<li>Dai: <a href="notes/Lecture_02_Notes_Dai.tex">tex</a>, <a href="notes/Lecture_02_Notes_Dai.pdf">pdf</a></li>
	<li>Huang: <a href="notes/Lecture_03_Notes_Huang.tex">tex</a>, <a href="notes/Lecture_03_Notes_Huang.pdf">pdf</a></li>
    <li></li>
	<li>Gao: <a href="notes/Lecture_04_Notes_Gao.tex">tex</a>, <a href="notes/Lecture_04_Notes_Gao.pdf">pdf</a></li>
	<li>Ulle: <a href="notes/Lecture_05_Notes_Ulle.tex">tex</a>, <a href="notes/Lecture_05_Notes_Ulle.pdf">pdf</a></li>
	<li>Fan: <a href="notes/Lecture_06_Notes_Fan.tex">tex</a>, <a href="notes/Lecture_06_Notes_Fan.pdf">pdf</a></li>
	<li>Hsueh: <a href="notes/Lecture_07_Notes_Hsueh.tar.gz">tex</a>, <a href="notes/Lecture_07_Notes_Hsueh.pdf">pdf</a></li>
    <li></li>
	<li>Ji: <a href="notes/Lecture_08_Notes_Ji.tex">tex</a>, <a href="notes/Lecture_08_Notes_Ji.pdf">pdf</a></li>
    <li>(None)</li>
	<li>Nguyen: <a href="notes/Lecture_10_Notes_Nguyen.tex">tex</a>, <a href="notes/Lecture_10_Notes_Nguyen.pdf">pdf</a></li>
	<li>Pei-Chen: <a href="notes/Lecture_11_Notes_PCChen.tex">tex</a>, <a href="notes/Lecture_11_Notes_PCChen.pdf">pdf</a></li>
    <li></li>
	<li>Paisley: <a href="notes/Lecture_12_Notes_Paisley.tex">tex</a>, <a href="notes/Lecture_12_Notes_Paisley.pdf">pdf</a></li>
	<li>Shuyang: <a href="notes/Lecture_13_Notes_ShLi.tex">tex</a>, <a href="notes/Lecture_13_Notes_ShLi.pdf">pdf</a></li>
	<li>(Coming soon...)</li>
	<li>(Coming soon...)</li>
</ul>
</div>
<div style="float: right; width: 25%;">
<ul>
    <li>Notetaker 3</li>
	<li>(No Notetaker)</li>
    <li></li>
    <li>Liu: <a href="notes/Lecture_02_Notes.tex">tex</a>, <a href="notes/Lecture_02_Notes_Liu.pdf">pdf</a></li>
	<li>Wang: <a href="notes/Lecture_03_Notes_Wang.tex">tex</a>, <a href="notes/Lecture_03_Notes_Wang.pdf">pdf</a></li>
    <li></li>
	<li>Filshtein: <a href="notes/Lecture_04_Notes_Filshtein.tex">tex</a>, <a href="notes/Lecture_04_Notes_Filshtein.pdf">pdf</a></li>
    <li>(None)</li>
    <li>(None)</li>
	<li>Lee: <a href="notes/Lecture_07_Notes_Lee.tex">tex</a>, <a href="notes/Lecture_07_Notes_Lee.pdf">pdf</a></li>
    <li></li>
    <li>Chen: <a href="notes/Lecture_08_Notes_Chen.tex">tex</a>, <a href="notes/Lecture_08_Notes_Chi.pdf">pdf</a></li>
    <li>(None)</li>
    <li>(None)</li>
	<li>(None)</li>
    <li></li>
	<li>Li: <a href="notes/Lecture_12_Notes_Li.tex">tex</a>, <a href="notes/Lecture_12_Notes_Li.pdf">pdf</a></li>
	<li>(None)</li>
	<li>(Coming soon...)</li>
	<li>(Coming soon...)</li>
</ul>
</div>
<br/><br/>
<h3>References</h3>
<p>Lecture 04 References (Bayes Lecture 1):</p>
<ul>
    <li><a href="http://bayesian.org/events/valencia/1979JRSSB.pdf">Bernardo, J.M. (1979) Reference Posterior Distributions for Bayesian Inference. JRSSB, 41, 2, pp. 113-147</a></li>
    <li><a href="http://www.jstor.org/stable/2984298">Welch, B.L. and Peers, H.W. (1963) On formulae for confidence points based on integrals of weighted likelihoods. JRRSB, 25-2, pp. 318-329</a></li>
    <li><a href="http://projecteuclid.org/euclid.ba/1340371036">Goldstein, M. (2006) Subjective Bayesian Analysis: Principles and Practice. Bayesian Analysis, 1-3, pp. 403-420.</a></li>
</ul>

<p>Lecture 05 References (Bayes Lecture 2):</p>
<ul>
    <li><a href="http://www.people.fas.harvard.edu/~plam/teaching/methods/mcmc/mcmc.pdf">Patrick Lam's MCMC Overview</a></li>
    <li><a href="https://vpn.lib.ucdavis.edu/content/m28q35/,DanaInfo=www.springerlink.com+#section=59276&page=11&locus=51">Hoff, P.D. (2009) A First Course in Bayesian Statistical Methods (Ch 7: Multivariate Normal, Ch 10: Metropolis-Hastings)</a></li>
    <li><a href="http://www.mcmchandbook.net/HandbookChapter1.pdf">Geyer, C.J. (2011) Introduction to MCMC in The MCMC Handbook, Chapman and Hall/CRC.</a></li> 
    <li><a href="http://www.dartmouth.edu/~chance/teaching_aids/books_articles/probability_book/Chapter11.pdf">Grinstead, C.M., Snell, J.L. (1997) Introduction to Probability (Ch 11: Markov Chains), American Mathematical Society.</a></li>
<!--http://arxiv.org/pdf/math/0404033.pdf-->
</ul>

<p>Lecture 06 References (Bayes Lecture 3):</p>
<ul>
    <li><a href="http://www.stat.cmu.edu/~acthomas/724/Cook.pdf">Cook, S.R., Gelman, A., Rubin, D.B. (2006) Validation of Software for Bayesian Models Using Posterior Quantiles. Journal of Computational and Graphical Statistics, 15, 3, 675-692.</a></li> 
    <li><a href="http://streaming.stat.iastate.edu/~stat444x_B/Literature/ChibGreenberg.pdf">Chib, S., Greenberg, E. (1995) Understanding the Metropolis-Hastings Algorithm. The American Statistician, 49, 4, 327-335.</a></li> 
</ul>

<p>Lecture 07 References (Bayes Lecture 4):</p>
<ul>
    <li><a href="http://www2.warwick.ac.uk/fac/sci/statistics/staff/academic-research/latuszynski/aap1101-028r1a0.pdf">Latuszynski, K, Roberts, G.O., Rosenthal, J.S. (2011) Adaptive Gibbs samplers and related MCMC methods. Annals of Applied Probability, 23, 1, 66-98.</a></li> 
    <li><a href="http://www.stat.umn.edu/geyer/f05/8931/c.pdf">Geyer, C.J. (1991) Markov Chain Monte Carlo Maximum Likelihood. Proceeding of the Interface.</a></li>
</ul>

<p>Lecture 08 References (Big Data Lecture 1):</p>
<ul>
    <li><a href="http://projecteuclid.org/euclid.aos/1176344552">Efron, B. (1979) Bootstrap Methods: Another Look at the Jackknife. The Annals of Statistics. 7, 1, 1-26.</a></li> 
    <li><a href="http://arxiv.org/abs/1112.5016">Kleiner, A., Talwalkar, A., Sarkar, P., Jordan, M.I. (2011) A Scalable Bootstrap for Massive Data. arXiv: 1112.5016</a></li> 
</ul>

<p>Lecture 09 References (Big Data Lecture 2):</p>
<ul>
    <li><a href="http://research.google.com/archive/mapreduce.html">Dean, J. and Ghemawat, S. (2004) MapReduce: Simplified Data Processing on Large Clusters. In: OSDI'04: Sixth Symposium on Operating System Design and Implementation, San Francisco, CA.</a></li>
    <li><a href="http://research.google.com/archive/papers/mapreduce-sigmetrics09-tutorial.pdf">MapReduce Tutorial (Strategies)</a></li>
    <li><a href="http://www.cs.rutgers.edu/~pxk/417/notes/content/mapreduce.html">MapReduce Tutorial (More Detail)</a></li>
</ul>

<p>Lecture 10 References (Big Data Lecture 3):</p>
<ul>
    <li><a href="http://aws.amazon.com/articles/5249664154115844">Apache Hive Tutorial: Google ngrams</a></li>
</ul>

<p>Lecture 11 References (Big Data Lecture 4):</p>
<ul>
    <li><a href="http://docs.python.org/tutorial">Python Tutorial</a></li>
</ul>

<p>Lecture 12 References (Optimization + EM Lecture 1):</p>
<ul>
    <li><a href="http://www.jstor.org/stable/2984875">Dempster, A.P., Laird, N.M. and Rubin, D.B. (1977) Maximum Likelihood from Incomplete Data via the EM Algorithm. Journal of the Royal Statistical Society, Series B. 39-1, 1-38.</a></li>
</ul>

<p>Lecture 13 References (Optimization + EM Lecture 2):</p>
<ul>
    <li><a href="http://projecteuclid.org/euclid.aos/1176346060">Wu, C.F.J. (1977) On the Convergence Properties of the EM Algorithm. The Annals of Statistics. 11-1, 95-103.</a></li>
</ul>

<p>Lecture 14 References (Optimization + EM Lecture 3):</p>
<ul>
    <li><a href="www.jstor.org/stable/2337198">Meng, X.-L. and Rubin, D.B. (1993) Maximum Likelihood Estimationn via the ECM Algorithm: A General Framework. Biometrika. 80-2, 267-278.</a></li>
    <li><a href="www.jstor.org/stable/1391097">Levine, R.A. and Casella, G. (2001) Implementations of the Monte Carlo EM Algorithm. Journal of Computational and Graphical Statistics. 10-3, 422-439.</a></li>
</ul>

<p>Lecture 15 References (Optimization + EM Lecture 4):</p>
<ul>
    <li><a href="http://www.stat.ucdavis.edu/~pdbaines/pdfs/IEM_AOS_Paper.pdf">Baines, P.D., Meng, X.-L. and Xie, X. (2013) Accelerating EM via Interweaving: The IEM Algorithm.</a></li>
    <li><a href="http://www.stat.harvard.edu/Faculty_Content/meng/jcgs.2011-article.pdf">Yu, Y. and Meng, X.-L. (2013) To Center or Not to Center: That is Not the Question – An Ancillarity-Sufficiency Interweaving Strategy (ASIS) for Boosting MCMC Efficiency (with discussion). Journal of Computational and Graphical Statistics. 20, 531–570.</a></li>
</ul>

<p>Happy coding! :)</p>
      </section>

    </div>
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->
    
  </body>
</html>
